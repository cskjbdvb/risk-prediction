import numpy as np
import pandas as pd
from sklearn.impute import KNNImputer
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

# ===================== å‚æ•°é…ç½® =====================
INPUT_FILE = "D:\\ç ”äºŒ2\\è®ºæ–‡æ’°å†™\\æ•°æ®åˆå¹¶\\æ ‡å‡†åŒ–.xlsx"  # æ›¿æ¢ä¸ºä½ çš„æ•°æ®æ–‡ä»¶è·¯å¾„
SHEET_NAME = "å¡«å……ç¼ºå¤±å€¼"  # å·¥ä½œè¡¨åç§°
ID_COL = 'SEQN'  # IDåˆ—å
LABEL_COLS = ['DIQ010 - åŒ»ç”Ÿå‘Šè¯‰ä½ æœ‰ç³–å°¿ç—…', 'MCQ160c - æ›¾è¢«å‘ŠçŸ¥è‡ªå·±æ‚£æœ‰å† å¿ƒç—…', 'MCQ160f - æ›¾è¢«å‘ŠçŸ¥ä½ ä¸­é£','æ˜¯å¦è¢«å‘ŠçŸ¥æ‚£æœ‰COPDã€è‚ºæ°”è‚¿æˆ–æ…¢æ€§æ”¯æ°”ç®¡ç‚']  # å››ä¸ªæ ‡ç­¾åˆ—å
K_VALUES = [15,17,19,21,23]  # è¦æµ‹è¯•çš„Kå€¼èŒƒå›´
TEST_SIZE = 0.2  # ç”¨äºè¯„ä¼°çš„æµ‹è¯•é›†æ¯”ä¾‹
RANDOM_STATE = 42  # éšæœºç§å­


# ==================================================

def load_data():
    """åŠ è½½æ•°æ®"""
    df = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)
    print("\n=== æ•°æ®åŠ è½½æˆåŠŸ ===")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print("\nå‰3è¡Œæ•°æ®é¢„è§ˆ:")
    print(df.head(3))
    return df


def prepare_data(df):
    """å‡†å¤‡æ•°æ®ï¼šåˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾"""
    # åˆ†ç¦»IDå’Œæ ‡ç­¾
    ids = df[ID_COL]
    labels = df[LABEL_COLS]

    # ç‰¹å¾åˆ—ï¼ˆæ‰€æœ‰éIDéæ ‡ç­¾åˆ—ï¼‰
    features = df.drop(columns=[ID_COL] + LABEL_COLS)

    # æ‰¾å‡ºæœ‰ç¼ºå¤±å€¼çš„åˆ—
    missing_cols = features.columns[features.isna().any()].tolist()
    complete_cols = [col for col in features.columns if col not in missing_cols]

    print(f"\næœ‰ç¼ºå¤±å€¼çš„ç‰¹å¾åˆ— ({len(missing_cols)}ä¸ª): {missing_cols}")
    print(f"å®Œæ•´æ— ç¼ºçš„ç‰¹å¾åˆ— ({len(complete_cols)}ä¸ª): {complete_cols}")

    return features, missing_cols, complete_cols, ids, labels


def evaluate_imputation(original, imputed, mask):
    """è¯„ä¼°å¡«å……æ•ˆæœ"""
    # è·å–æœ‰æ•ˆå€¼ç´¢å¼•
    valid_mask = mask & ~np.isnan(original) & ~np.isnan(imputed)

    if np.sum(valid_mask) == 0:
        return np.nan, np.nan

    # åªè®¡ç®—æœ‰æ•ˆå€¼
    mse = mean_squared_error(original[valid_mask], imputed[valid_mask])
    mae = mean_absolute_error(original[valid_mask], imputed[valid_mask])
    return mse, mae


def knn_impute_with_evaluation(features, missing_cols, complete_cols, k_values):
    """KNNå¡«å…… + è¯„ä¼°ï¼ˆåªå¤„ç†æœ‰ç¼ºå¤±å€¼çš„åˆ—ï¼‰"""
    # å¤åˆ¶æ•°æ®ç”¨äºè¯„ä¼°
    X = features.copy()

    # 1. æ‰¾å‡ºæ‰€æœ‰æœ‰ç¼ºå¤±å€¼çš„è¡Œå’Œåˆ—
    missing_mask = pd.DataFrame(np.isnan(X[missing_cols]),
                                index=X.index,
                                columns=missing_cols)

    # 2. äººä¸ºåˆ¶é€ æ›´å¤šç¼ºå¤±å€¼ç”¨äºè¯„ä¼°
    evaluation_mask = pd.DataFrame(np.zeros_like(X[missing_cols], dtype=bool),
                                   index=X.index,
                                   columns=missing_cols)

    for col in missing_cols:
        # æ‰¾å‡ºè¯¥åˆ—éç¼ºå¤±çš„ç´¢å¼•
        non_missing_idx = X[col].dropna().index
        # ä»ä¸­éšæœºé€‰æ‹©20%ä½œä¸ºè¯„ä¼°ç”¨ç¼ºå¤±å€¼
        eval_idx = np.random.choice(non_missing_idx,
                                    size=int(len(non_missing_idx) * TEST_SIZE),
                                    replace=False)
        evaluation_mask.loc[eval_idx, col] = True

    # åˆå¹¶åŸå§‹ç¼ºå¤±å’Œè¯„ä¼°ç¼ºå¤±
    total_mask = missing_mask | evaluation_mask

    # å¤‡ä»½çœŸå®å€¼ï¼ˆä»…ç¼ºå¤±åˆ—ï¼‰
    X_true = X[missing_cols].copy()
    X_missing = X.copy()
    X_missing[total_mask] = np.nan

    # æ ‡å‡†åŒ–æ•°æ®ï¼ˆä»…å¯¹ç¼ºå¤±åˆ—ï¼‰
    scaler = StandardScaler()
    X_scaled_missing = pd.DataFrame(scaler.fit_transform(X_missing[missing_cols]),
                                    columns=missing_cols,
                                    index=X_missing.index)

    # åˆå¹¶å®Œæ•´åˆ—ï¼ˆä¸å¤„ç†ï¼‰
    X_scaled = pd.concat([X[complete_cols], X_scaled_missing], axis=1)

    # ç½‘æ ¼æœç´¢æœ€ä½³Kå€¼
    results = []
    best_k = None
    best_score = float('inf')

    print("\n=== å¼€å§‹KNNå¡«å……è¯„ä¼° ===")
    for k in tqdm(k_values, desc="è¯„ä¼°ä¸åŒKå€¼"):
        try:
            # ä½¿ç”¨KNNå¡«å……ï¼ˆä»…å¤„ç†ç¼ºå¤±åˆ—ï¼‰
            imputer = KNNImputer(n_neighbors=k)
            X_imputed_missing = imputer.fit_transform(X_scaled[missing_cols])
            X_imputed_missing = pd.DataFrame(scaler.inverse_transform(X_imputed_missing),
                                             columns=missing_cols,
                                             index=X_missing.index)

            # åˆå¹¶å›å®Œæ•´åˆ—
            X_imputed = pd.concat([X[complete_cols], X_imputed_missing], axis=1)

            # è¯„ä¼°å¡«å……æ•ˆæœï¼ˆä»…ç¼ºå¤±åˆ—ï¼‰
            mse, mae = evaluate_imputation(X_true.values,
                                           X_imputed[missing_cols].values,
                                           evaluation_mask.values)

            if not np.isnan(mse):  # å¿½ç•¥æ— æ•ˆè¯„ä¼°
                results.append({'k': k, 'mse': mse, 'mae': mae})

                # é€‰æ‹©MSEæœ€å°çš„Kå€¼
                if mse < best_score:
                    best_score = mse
                    best_k = k
        except Exception as e:
            print(f"K={k}æ—¶å‡ºé”™: {str(e)}")
            continue

    # è¾“å‡ºè¯„ä¼°ç»“æœ
    results_df = pd.DataFrame(results)
    print("\n=== Kå€¼è¯„ä¼°ç»“æœ ===")
    print(results_df)
    print(f"\næœ€ä½³Kå€¼: {best_k} (æœ€ä½MSE: {best_score:.4f})")

    # ç”¨æœ€ä½³Kå€¼å¡«å……åŸå§‹æ•°æ®çš„æ‰€æœ‰ç¼ºå¤±å€¼ï¼ˆä»…ç¼ºå¤±åˆ—ï¼‰
    print("\n=== ä½¿ç”¨æœ€ä½³Kå€¼è¿›è¡Œæœ€ç»ˆå¡«å…… ===")
    final_imputer = KNNImputer(n_neighbors=best_k)
    X_final_missing = pd.DataFrame(scaler.fit_transform(features[missing_cols]),
                                   columns=missing_cols,
                                   index=features.index)
    X_final_missing = final_imputer.fit_transform(X_final_missing)
    X_final_missing = pd.DataFrame(scaler.inverse_transform(X_final_missing),
                                   columns=missing_cols,
                                   index=features.index)

    # åˆå¹¶å›å®Œæ•´åˆ—
    X_final = pd.concat([features[complete_cols], X_final_missing], axis=1)

    return X_final, best_k, results_df


def save_results(final_df, ids, labels, best_k, results_df):
    """ä¿å­˜ç»“æœ"""
    # åˆå¹¶å›IDå’Œæ ‡ç­¾åˆ—
    final_df[ID_COL] = ids.values
    for label in LABEL_COLS:
        final_df[label] = labels[label].values

    # è°ƒæ•´åˆ—é¡ºåº
    cols = [ID_COL] + LABEL_COLS + [col for col in final_df.columns if col not in [ID_COL] + LABEL_COLS]
    final_df = final_df[cols]

    # ä¿å­˜å¡«å……åçš„æ•°æ®
    output_file = "D:\\ç ”äºŒ2\\è®ºæ–‡æ’°å†™\\æ•°æ®åˆå¹¶\\KNN.xlsx"
    final_df.to_excel(output_file, index=False)

    # ä¿å­˜è¯„ä¼°ç»“æœ
    eval_file = "D:\\ç ”äºŒ2\\è®ºæ–‡æ’°å†™\\æ•°æ®åˆå¹¶\\KNNç³»æ•°.xlsx"
    results_df.to_excel(eval_file, index=False)

    print("\n=== å¤„ç†å®Œæˆ ===")
    print(f"âœ… å¡«å……åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {eval_file}")
    print(f"ğŸ”„ ä½¿ç”¨çš„Kå€¼: {best_k}")
    print("\nå¡«å……åæ•°æ®é¢„è§ˆ:")
    print(final_df.head(3))


if __name__ == "__main__":
    # 1. åŠ è½½æ•°æ®
    df = load_data()

    # 2. å‡†å¤‡æ•°æ®
    features, missing_cols, complete_cols, ids, labels = prepare_data(df)

    # 3. KNNå¡«å…… + è¯„ä¼°ï¼ˆåªå¤„ç†ç¼ºå¤±åˆ—ï¼‰
    final_features, best_k, results_df = knn_impute_with_evaluation(
        features, missing_cols, complete_cols, K_VALUES)

    # 4. ä¿å­˜ç»“æœ
    save_results(final_features, ids, labels, best_k, results_df)