import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# ===================== å¿…é¡»ä¿®æ”¹çš„é…ç½® =====================
INPUT_FILE = "D:\\ç ”äºŒ2\\è®ºæ–‡æ’°å†™\\17-23å¹´æ•°æ®\\å¼‚å¸¸å€¼å¤„ç†ã€å¡«å……ç¼ºå¤±å€¼ã€åˆ é™¤éƒ¨åˆ†æ— å…³ç‰¹å¾.xlsx"  # æ‚¨çš„Excelæ–‡ä»¶è·¯å¾„
SHEET_NAME = "Sheet4"  # å·¥ä½œè¡¨åç§°
ID_COL = 'å“åº”è€…åºåˆ—å·'  # IDåˆ—åç§°
LABEL_COLS = ['æ›¾è¢«å‘ŠçŸ¥ä½ æ‚£æœ‰æ…¢æ€§é˜»å¡æ€§è‚ºç—…ã€è‚ºæ°”è‚¿ã€ChB', 'æ›¾è¢«å‘ŠçŸ¥ä½ ä¸­é£', 'æ›¾è¢«å‘ŠçŸ¥è‡ªå·±æ‚£æœ‰å† å¿ƒç—…','åŒ»ç”Ÿå‘Šè¯‰ä½ æœ‰ç³–å°¿ç—…ï¼ˆ1æ˜¯çš„ï¼Œ0ä¸ï¼Œæ‹’ç»ï¼Œä¸çŸ¥é“ï¼‰']  # å››ä¸ªæ ‡ç­¾åˆ—å
#CATEGORICAL_THRESHOLD = 8  # å”¯ä¸€å€¼è¶…è¿‡æ­¤æ•°è§†ä¸ºè¿ç»­å‹
# æ‰‹åŠ¨æŒ‡å®šç‰¹æ®Šç‰¹å¾ç±»å‹ï¼ˆå¯é€‰ï¼‰
MANUAL_TYPES = {
    # 'feature_name': 'binary'/'multi'/'continuous'
    # ç¤ºä¾‹ï¼š
    # 'gender': 'binary',    # å¼ºåˆ¶ä½œä¸ºäºŒåˆ†ç±»
    # 'blood_type': 'multi', # å¼ºåˆ¶ä½œä¸ºå¤šåˆ†ç±»
    # 'age': 'continuous'    # å¼ºåˆ¶ä½œä¸ºè¿ç»­å‹
}


# ========================================================

def load_data():
    """åŠ è½½æ•°æ®å¹¶æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯"""
    df = pd.read_excel(INPUT_FILE, sheet_name=SHEET_NAME)
    print("\n=== æ•°æ®åŠ è½½æˆåŠŸ ===")
    print(f"æ€»æ ·æœ¬æ•°: {len(df)} | æ€»ç‰¹å¾æ•°: {len(df.columns) - 5}")
    print("\nå‰3è¡Œæ•°æ®é¢„è§ˆ:")
    print(df.head(3))
    return df


def strict_feature_identification(df):
    """ä¸¥æ ¼çš„ç‰¹å¾ç±»å‹è¯†åˆ«"""
    feature_types = {}
    all_features = [col for col in df.columns if col not in [ID_COL] + LABEL_COLS]

    for feature in all_features:
        # ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„ç±»å‹
        if feature in MANUAL_TYPES:
            feature_types[feature] = MANUAL_TYPES[feature]
            continue

        # è·å–éç©ºå”¯ä¸€å€¼
        unique_vals = df[feature].dropna().unique()
        num_unique = len(unique_vals)

        # ä¸¥æ ¼ç±»å‹åˆ¤æ–­é€»è¾‘
        if num_unique == 2 and set(unique_vals) == {0, 1}:
            feature_types[feature] = "binary"  # å·²ç»æ˜¯0/1ç¼–ç çš„äºŒåˆ†ç±»
        elif num_unique == 2:
            feature_types[feature] = "binary"  # äºŒåˆ†ç±»ä½†æœªç¼–ç 
        elif num_unique <= 8:  # å‡è®¾ç±»åˆ«æ•°â‰¤5ä¸ºåˆ†ç±»å˜é‡
            feature_types[feature] = "multi"  # å¤šåˆ†ç±»
        elif pd.api.types.is_numeric_dtype(df[feature]):
            feature_types[feature] = "continuous"  # è¿ç»­å‹
        else:
            feature_types[feature] = "multi"  # é»˜è®¤ä½œä¸ºå¤šåˆ†ç±»

    return feature_types


def process_data(df, feature_types):
    """æ‰§è¡Œç‰¹å¾å¤„ç†"""
    # åˆ†ç±»ç‰¹å¾
    binary_feats = [f for f, t in feature_types.items() if t == "binary"]
    multi_feats = [f for f, t in feature_types.items() if t == "multi"]
    continuous_feats = [f for f, t in feature_types.items() if t == "continuous"]

    print("\n=== ç‰¹å¾ç±»å‹ç¡®è®¤ ===")
    print(f"âœ… äºŒåˆ†ç±»ç‰¹å¾ (ä¿æŒåŸæ ·): {binary_feats}")
    print(f"ğŸ”¥ å¤šåˆ†ç±»ç‰¹å¾ (ç‹¬çƒ­ç¼–ç ): {multi_feats}")
    print(f"ğŸ“Š è¿ç»­å‹ç‰¹å¾ (æ ‡å‡†åŒ–): {continuous_feats}")

    # åˆ›å»ºå¤„ç†ç®¡é“
    preprocessor = ColumnTransformer(
        transformers=[
            ('continuous', StandardScaler(), continuous_feats),
            ('multi_cat', OneHotEncoder(drop='first', sparse_output=False), multi_feats)
        ],
        remainder="passthrough"  # ä¿æŒå…¶ä»–åˆ—ä¸å˜
    )

    # åº”ç”¨è½¬æ¢
    features_to_process = df.drop(columns=[ID_COL] + LABEL_COLS)
    processed_array = preprocessor.fit_transform(features_to_process)

    # æ„å»ºæ–°ç‰¹å¾åç§°
    new_columns = continuous_feats.copy()  # è¿ç»­å‹ç‰¹å¾åä¸å˜

    # æ·»åŠ ç‹¬çƒ­ç¼–ç åçš„åˆ—å
    if multi_feats:
        ohe = preprocessor.named_transformers_['multi_cat']
        for i, col in enumerate(multi_feats):
            categories = ohe.categories_[i][1:]  # ä½¿ç”¨drop='first'
            new_columns.extend([f"{col}_{cat}" for cat in categories])

    # æ·»åŠ äºŒåˆ†ç±»ç‰¹å¾å
    new_columns.extend(binary_feats)

    # åˆ›å»ºæœ€ç»ˆDataFrame
    processed_df = pd.DataFrame(processed_array, columns=new_columns)

    # æ·»åŠ IDå’Œæ ‡ç­¾åˆ—
    processed_df[ID_COL] = df[ID_COL].values
    for label in LABEL_COLS:
        processed_df[label] = df[label].values

    # ä¼˜åŒ–åˆ—é¡ºåº
    final_order = (
            [ID_COL] + LABEL_COLS +
            binary_feats + continuous_feats +
            [c for c in new_columns if c not in binary_feats + continuous_feats]
    )

    return processed_df[final_order]


def save_results(processed_df):
    """ä¿å­˜å¤„ç†ç»“æœ"""
    output_file = "D:\\ç ”äºŒ2\\è®ºæ–‡æ’°å†™\\17-23å¹´æ•°æ®\\æ ‡å‡†åŒ–.xlsx"
    processed_df.to_excel(output_file, index=False)

    print("\n=== å¤„ç†ç»“æœ ===")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶å·²ä¿å­˜: {output_file}")
    print(f"ğŸ”„ å½¢çŠ¶å˜åŒ–: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ— â†’ {processed_df.shape}")
    print("\nå¤„ç†å3è¡Œæ•°æ®é¢„è§ˆ:")
    print(processed_df.head(3))


if __name__ == "__main__":
    # æ‰§è¡Œæµç¨‹
    df = load_data()
    feature_types = strict_feature_identification(df)
    final_data = process_data(df, feature_types)
    save_results(final_data)
    print("\nğŸ‰ å¤„ç†å®Œæˆï¼æ‰€æœ‰ç‰¹å¾å·²æ­£ç¡®è½¬æ¢")



